* TD buffer get which s_
    > current thinking the state decide sell should be the last state
    > which cause the issue:
        all the boosttrap rely on s_ of the sell record, which 
    >   1. does not have training at all 
    >   2. the av of which is actually same as the state of start no holding, confusing if the the algorithm, definitely  me  
    
    The ideal situation is 
    if the get recordm the buffer touch end
        1. get 1 record s s_
        2. get more than two record s_ from the record second last one should be n-2
    
    after modify, this thinking is:
    >   1. since the original test always use td =1 , the new version and the old version have the same effect
    >   2. the OS_s_0_reward implementation is totoally wrong, need to check the test restult. if no special finding remove that 

* important finding
    PPO policy loss is different with PG policy loss , no minue is needed

* whether need the terminate state
* estable model md try CNN not Resnet
* understand why there is difference in last test of OS1 and OS2

 